{
  "training": {
    "do_train": true,
    "num_lm_train_epochs": 2,
    "gradient_accumulation_steps": 1,
    "per_gpu_train_lm_batch_size": 0,
    "per_gpu_train_batch_size": 16,
    "only_lm": false,
    "optimizer": "adam",
    "learning_rate": 5e-5,
    "adam_epsilon": 1e-8,
    "warmup_steps": 0,
    "max_norm": 3.0,
    "weight_decay": 0.0,
    "max_grad_norm": 1.0,
    "epochs": 70,
    "batches_per_report": 200,
    "batches_per_sampling": 500,
    "evaluate_during_training": true,
    "save_steps": 999999999,
    "lm_max_steps": -1,
    "epoch_max_steps": -1,
    "max_steps":-1,
    "random_seed": 23492,
    "num_train_epochs": 128.0,
    "per_gpu_train_cycle_ar_cocon_recon_batch_size": 2,
    "lambda_self_cocon_lm_loss": 1.0,
    "lambda_hist_cocon_lm_loss": 0.18,
    "lambda_aspects_control_loss": 0.2,
    "lambda_opinions_control_loss": 0.2,
    "epoch_ind_to_start_hist_cocon_lm": 0,
    "step_ind_to_start_hist_cocon_lm": 0,
    "transform_h_after_layernorm": false,
    "epoch_ind_to_start_cycle_ar_cocon_recon": 0,
    "lambda_cycle_ar_cocon_recon_lm_loss": 0.0
  },
  "data": {
    "labeled": "data/crop/SemEval/train.json",
    "unlabeled": "data/crop/yelp/sentiment.train.0",
    "labeled_test": "data/crop/SemEval/test.json",
    "unlabeled_test": "data/crop/yelp/sentiment.test.0",
    "overwrite_cache": false,
    "src_vocab": "data/vocab/vocab",
    "tgt_vocab": "data/vocab/vocab",
    "eval_output_filename": "eval_results.txt",
    "prepended_text_to_remove": null,
    "polarity_vocab": {"NEG": 1, "NEU": 2,"POS": 3},
    "share_vocab": true,
    "attribute_vocab": "data/yelp/ngram.15.attribute",
    "ngram_attributes": true,
    "cs_len": 14,
    "hs_len": 2,
    "tis_len": 14,
    "gen_cs_len": null,
    "gen_hs_len": null,
    "gen_tis_len": null,
    "generate_length": 20,
    "temperature": 1.0,
    "k":0,
    "p": 0.9,
    "repetition_penalty": 1.0,
    "num_return_sequences": 1,
    "min_hs_tis_split_offset": -1,
    "max_hs_tis_split_offset": 2,
    "per_gpu_eval_batch_size": 16,
    "self_cocon_lm_cs_mask_prob": 0.0,
    "self_token_mask_prob": 1.0,
    "self_cocon_lm_mutual_exc_mask": false,
    "track_loss_gradnorms": false,
    "track_hist_cocon_lm_loss": false,
    "batch_size": 16,
    "save_total_limit": 10,
    "logging_steps": 300,
    "max_len": 50,
    "working_dir": "working_dir",
    "joint_of_aspect_opinion": 982,
    "POS_JOINTER": " -------- ",
    "NEU_JOINTER": " -------- ",
    "NEG_JOINTER": " -------- ",
    "INNER_JOINTER": " AND ",
    "SUB_TEXT_SEG": "</",
    "SUB_TEXT_SEG_ID": 7359,
    "START_END_PAD": "<|endoftext|>",
    "random_seed": 23492,
    "local_rank": -1,
    "no_cuda": false,
    "do_cocon_compute": true,
    "line_by_line_hs": false,
    "line_by_line_cs": false,
    "use_attn_mask": true,
    "compose_triples": true
  },
    "model": {
        "model_type": "gpt2",
        "model_name_or_path": "gpt2-medium",
        "output_dir": "save_models/ABS_CTG",
        "cache_dir": null,
        "block_size": -1,
        "output_meanvars": true,
        "compute_meanvars_before_layernorm": false,
        "output_hidden_for_cocon_after_block_ind": 6,
        "use_only_last_cocon_output_for_ar": false,
        "emb_dim": 128,
        "attention": false,
        "encoder": "lstm",
        "src_hidden_dim": 512,
        "src_layers": 1,
        "bidirectional": true,
        "tgt_hidden_dim": 512,
        "tgt_layers": 1,
        "decode": "greedy",
        "dropout": 0.2
    },
    "evaluate": {
      "eval_compute_without_checkpoint": false,
      "eval_all_checkpoints": false,
      "sentricon_output_filename": "sentricon_output.txt",
      "append_sentricon_output_files": false,
      "sentricon_output_jsonl_filename": "sentricon_output.jsonl",
      "cocon_compute_history_source_data_file": "data/gpt2output/webtext.valid.jsonl",
      "prepend_bos_token_to_line": false,
      "num_cocon_generate": 100
    }
}
